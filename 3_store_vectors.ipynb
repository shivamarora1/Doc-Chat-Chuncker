{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/document-extractor/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "### * Script to insert content in vector database.\n",
    "### * Script assumes data is stored in .csv file.\n",
    "\n",
    "from pymilvus import connections, Collection\n",
    "from pymilvus import utility, FieldSchema, CollectionSchema, DataType, Collection\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FILE_NAME = \"tata_punch_owner_manual.pdf\"\n",
    "FOLDER_NAME = FILE_NAME.split(\".\")[0]\n",
    "CSV_FILE_LINK = f\"output/{FOLDER_NAME}/{FOLDER_NAME}_csv.csv\"\n",
    "COLLECTION_NAME = \"rag_vs\"\n",
    "\n",
    "MILVUS_TOKEN = os.getenv(\"MILVUS_TOKEN\")\n",
    "MILVUS_URI = os.getenv(\"MILVUS_URI\")\n",
    "DIMENSION = 384\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection rag_vs already exists.\n"
     ]
    }
   ],
   "source": [
    "collection: Collection = None\n",
    "\n",
    "### Creating a collection\n",
    "connections.connect(uri=MILVUS_URI, token=MILVUS_TOKEN)\n",
    "\n",
    "if not utility.has_collection(collection_name=COLLECTION_NAME):\n",
    "    print(f\"collection {COLLECTION_NAME} not found. creating one.\")\n",
    "    fields = [\n",
    "        FieldSchema(\n",
    "            name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True\n",
    "        ),  # id is auto=increment\n",
    "        FieldSchema(name=\"content\", dtype=DataType.VARCHAR, max_length=65535),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=DIMENSION),\n",
    "        FieldSchema(name=\"page_num\", dtype=DataType.INT64),\n",
    "        FieldSchema(name=\"image_url\", dtype=DataType.VARCHAR, max_length=1000),\n",
    "        FieldSchema(name=\"file_name\", dtype=DataType.VARCHAR, max_length=200),\n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields)\n",
    "    collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
    "\n",
    "    index_params = {\n",
    "        \"metric_type\": \"L2\",\n",
    "        \"index_type\": \"IVF_FLAT\",\n",
    "        \"params\": {\"nlist\": 1536},\n",
    "    }\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    collection.load()\n",
    "else:\n",
    "    print(f\"collection {COLLECTION_NAME} already exists.\")\n",
    "    collection = Collection(name=COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/document-extractor/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "inserted... 127 contents\n",
      "\n",
      "inserted... 255 contents\n",
      "\n",
      "inserted... 383 contents\n",
      "\n",
      "inserted... 511 contents\n",
      "\n",
      "inserted... 639 contents\n",
      "\n",
      "inserted... 767 contents\n",
      "\n",
      "inserted... 895 contents\n",
      "\n",
      "inserted... 1023 contents\n",
      "\n",
      "inserted... 1151 contents\n",
      "\n",
      "inserted... 1279 contents\n",
      "\n",
      "inserted... 1407 contents\n",
      "\n",
      "inserted... 1535 contents\n",
      "\n",
      "inserted... 1663 contents\n",
      "\n",
      "inserted... 1791 contents\n",
      "\n",
      "inserted... 1919 contents\n",
      "\n",
      "inserted... 2047 contents\n",
      "\n",
      "inserted... 2175 contents\n",
      "\n",
      "inserted... 2303 contents\n",
      "\n",
      "inserted... 2431 contents\n"
     ]
    }
   ],
   "source": [
    "transformer = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "def csv_load(file):\n",
    "    with open(file, newline=\"\") as f:\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        for row in reader:\n",
    "            yield (row[0], row[1], row[2])\n",
    "\n",
    "\n",
    "def generate_embeddings(data: list[str]):\n",
    "    embeddings = transformer.encode(data)\n",
    "    return [x for x in embeddings]\n",
    "\n",
    "def insert_data(data):\n",
    "    embeddings = generate_embeddings(data[0]) if data[0] else []\n",
    "    ins = [\n",
    "        data[0],\n",
    "        embeddings,\n",
    "        data[1],\n",
    "        data[2],\n",
    "        data[3],\n",
    "    ]\n",
    "    collection.insert(ins)\n",
    "\n",
    "\n",
    "data_batch = [[], [], [],[]]\n",
    "\n",
    "count = 0\n",
    "\n",
    "for content, page_num, image_url in csv_load(CSV_FILE_LINK):\n",
    "    data_batch[0].append(content)\n",
    "    data_batch[1].append(int(page_num))\n",
    "    data_batch[2].append(image_url)\n",
    "    data_batch[3].append(FILE_NAME)\n",
    "    if len(data_batch[0]) % BATCH_SIZE == 0:\n",
    "        insert_data(data_batch)\n",
    "        data_batch = [[], [], [],[]]\n",
    "        print(f\"\\ninserted... {count} contents\")\n",
    "    count += 1\n",
    "\n",
    "if len(data_batch[0]) != 0:\n",
    "    insert_data(data_batch)\n",
    "\n",
    "collection.flush()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "document-extractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
